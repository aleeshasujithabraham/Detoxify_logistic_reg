# Detoxify — YouTube Comment Toxicity Analyzer

Detoxify is a full-stack web application that analyzes YouTube video comments for toxicity, sexism, and offensive language using a custom-trained logistic regression model. It provides a beautiful, interactive dashboard to help users identify and report harmful content.

## Features
- Paste any YouTube video URL and analyze the first 100 comments
- **Custom AI-powered toxicity detection** using a logistic regression model trained on your own dataset (see `backend/model_train.py`)
- Safety Analysis Dashboard — shows safe/flagged counts, severity breakdown (High/Medium/Low), and animated toxicity bar
- Filter tabs — view All, Safe, Flagged, or High Severity comments
- Severity badges on each comment card (color-coded: red for high, orange for medium, purple for low, green for safe)
- PDF Report Generation — download a branded evidence report with video info, summary stats, and a table of all flagged comments (username + comment + severity)
- Video info display (title, channel, views, likes, comment count)
- Modern glassmorphism UI with soft pinks, lavender & purple palette

## Project Structure
```
Detoxify/
│   README.md
│   requirements.txt
│
├── backend/
│   ├── app.py              # Flask backend, serves API and frontend
│   ├── model_train.py      # Script to train and save the logistic regression model
│   ├── logreg_model.joblib # Saved model (generated by model_train.py)
│   └── vectorizer.joblib   # Saved vectorizer (generated by model_train.py)
│
└── frontend/
	├── index.html          # Main UI
	├── script.js           # Frontend logic (fetches API, renders dashboard)
	└── style.css           # Styles (glassmorphism, gradients, etc.)
```

## How It Works
1. **Frontend**: User pastes a YouTube video URL and clicks Analyze. The UI sends a request to the backend.
2. **Backend**: 
   - Extracts the video ID and fetches comments using the YouTube Data API.
   - Each comment is vectorized and classified using the custom logistic regression model (see `backend/model_train.py`).
   - Returns analysis results (flagged/safe, severity, confidence) and video info to the frontend.
3. **Frontend**: Displays results in a dashboard, allows filtering, and can generate a PDF report.

## Setup Instructions

### 1. Get a YouTube API Key (Free)
1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project (or use an existing one)
3. Enable **YouTube Data API v3** from the API Library
4. Go to **Credentials** → **Create Credentials** → **API Key**
5. Copy the API key

### 2. Configure the API Key
Create a `.env` file in the project root (next to README.md) and add:
```
YOUTUBE_API_KEY=your_actual_api_key_here
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Train the Model (Optional: only if you want to retrain)
- Place your labeled dataset (CSV) in a known location and update the path in `backend/model_train.py`.
- Run:
```bash
cd backend
python model_train.py
```
This will generate `logreg_model.joblib` and `vectorizer.joblib` in the backend folder.

### 5. Run the Backend (serves both API and frontend)
```bash
cd backend
python app.py
```
Visit [http://127.0.0.1:5000](http://127.0.0.1:5000) in your browser.

## Requirements
- Python 3.8+
- Flask, Flask-CORS, google-api-python-client, python-dotenv, scikit-learn, pandas, joblib
- (optionally transformers/torch if you want to use the old model)

## Custom Model
- The backend uses a logistic regression model trained on your own dataset (see `backend/model_train.py`).
- You can retrain or swap the model by editing and rerunning `model_train.py`.
- The model and vectorizer are loaded at backend startup and used for all comment analysis.
- **[Add here: Briefly describe your dataset and what the labels mean, e.g., 1=sexist, 0=safe, etc.]**

## Credits
- Built for **Tink-Her-Hack** hackathon.
- UI/UX: Modern glassmorphism, animated gradients, and PDF export.
- **[Add here: Any additional contributors, dataset sources, or acknowledgments]**

---
*For questions or contributions, open an issue or pull request!*
The server starts at `http://127.0.0.1:5000`
> **Note:** The AI model (~500MB) downloads automatically on first run. Subsequent starts are instant.

### 5. Open the Frontend
Open `frontend/index.html` in your browser (just double-click it, or use Live Server in VS Code).

## Project Structure
```
Tink-Her-Hack/
├── backend/
│   └── app.py              # Flask API server + AI classifier
├── frontend/
│   ├── index.html           # Main page with dashboard & filters
│   ├── style.css            # Glassmorphism UI (women-friendly palette)
│   └── script.js            # Frontend logic + PDF generation
├── .env                     # Your API key (not committed)
├── .env.example             # Template for API key
├── .gitignore
├── requirements.txt
└── README.md
```

## Tech Stack
- **Backend:** Python, Flask, YouTube Data API v3
- **AI Model:** `cardiffnlp/twitter-roberta-base-offensive` (HuggingFace Transformers, PyTorch)
- **Frontend:** HTML, CSS, JavaScript (no frameworks)
- **PDF Generation:** jsPDF + jsPDF-AutoTable (client-side)
- **API:** Google YouTube Data API (free tier — 10,000 units/day)
